# Module 8 Quiz: Implementation & Change Management

**Total Points:** 20
**Passing Score:** 14/20 (70%)
**Time Limit:** 20 minutes

---

## Section 1: Multiple Choice (10 questions, 1 point each)

### Question 1
What is the PRIMARY reason AI implementations fail in customer service?

A) The AI technology isn't good enough
B) People and change management issues, not technical problems
C) Budget constraints
D) Lack of executive support

### Question 2
In a phased rollout, what is the main purpose of the "pilot" phase?

A) To delay full implementation
B) To test with a small group, learn, and adjust before scaling
C) To save money
D) To train all agents

### Question 3
When an agent says "AI will take my job," what is the BEST response approach?

A) Dismiss the concern as unfounded
B) Acknowledge the concern, provide evidence, and make commitments
C) Ignore it and move on
D) Promise nothing will change

### Question 4
What is a "champion" in AI implementation?

A) The vendor selling the AI tool
B) An early adopter who helps promote and support AI adoption with peers
C) The executive sponsor
D) The IT manager

### Question 5
Which metric is a LEADING indicator of AI implementation success?

A) Annual cost savings
B) Final ROI percentage
C) AI suggestion acceptance rate (early adoption signal)
D) Customer satisfaction after 6 months

### Question 6
How often should you communicate with agents during AI implementation?

A) Once at the beginning
B) Regularly throughout - before, during, and after launch
C) Only when problems arise
D) After implementation is complete

### Question 7
What is the recommended sequence for rolling out AI features?

A) All features at once for maximum impact
B) Start with customer-facing AI, then agent tools
C) Start with agent-assistance tools (lower risk), then customer-facing AI (higher risk)
D) Random order based on vendor recommendations

### Question 8
What creates psychological safety for agents during AI adoption?

A) Threatening consequences for non-adoption
B) Making mistakes during learning acceptable and encouraging honest feedback
C) Hiding problems from leadership
D) Comparing agents to each other publicly

### Question 9
In ROI calculation, what is "sensitivity analysis"?

A) Measuring agent emotions
B) Testing how ROI changes under different assumptions (conservative/optimistic)
C) Customer sentiment tracking
D) Agent satisfaction surveys

### Question 10
What should the first-year ROI expectation typically include?

A) Maximum possible savings from day one
B) Realistic benefits accounting for adoption curve and implementation costs
C) Only costs, no benefits expected
D) Double the vendor's promised returns

---

## Section 2: True/False (5 questions, 1 point each)

### Question 11
True or False: A successful pilot with 5-10 agents guarantees success when rolling out to 100 agents.

### Question 12
True or False: Agent buy-in is more important than executive support for AI implementation success.

### Question 13
True or False: Vanity metrics like "1000 AI responses generated" are useful for measuring implementation success.

### Question 14
True or False: The SARAH model (Shock, Anger, Resistance, Acceptance, Help) describes stages people go through during change.

### Question 15
True or False: Once AI is fully implemented, change management work is complete.

---

## Section 3: Scenario-Based Questions (5 questions, 1 point each)

### Question 16
**Scenario:** You're in week 2 of your AI pilot with 8 agents. Results show:
- 3 agents love it and use it constantly
- 3 agents use it occasionally
- 2 agents refuse to use it at all

**Question:** What should you do?

A) Force the 2 resistant agents to comply or face consequences
B) Investigate why the 2 agents are resistant, address concerns, and extend pilot if needed
C) Cancel the pilot - too much resistance
D) Ignore the 2 agents and proceed to full rollout

### Question 17
**Scenario:** Your ROI projection shows:
- Year 1: $50,000 investment, $30,000 benefit, Net: -$20,000
- Year 2: $20,000 investment, $80,000 benefit, Net: +$60,000
- Year 3: $20,000 investment, $100,000 benefit, Net: +$80,000

**Question:** How should you present this to executives?

A) Don't show Year 1 - it looks bad
B) Show the full 3-year picture with payback period and total ROI
C) Only show Year 3 projections
D) Wait until Year 2 to present

### Question 18
**Scenario:** A team lead reports that agents are accepting 95% of AI suggestions without editing them.

**Question:** What does this likely indicate?

A) The AI is perfect and agents trust it completely
B) Potential "rubber-stamping" - agents may not be reviewing suggestions carefully
C) Implementation is complete
D) Training was excellent

### Question 19
**Scenario:** You're creating a communication plan. Which sequence is BEST?

A) Day 1: Send email about new AI tool → Day 2: Turn it on
B) Week -4: Announce project → Week -2: Train champions → Week 0: Pilot launch → Week +2: Share early results
C) Turn on AI tool first → Explain later when agents ask questions
D) Wait until everything is perfect, then announce

### Question 20
**Scenario:** Six months after AI implementation:
- Cost per contact: Reduced 18% (target: 20%)
- Agent satisfaction: 3.8/5 (target: 4.0/5)
- CSAT: Improved 4% (target: 5%)
- AI usage: 78% daily active (target: 80%)

**Question:** How should you characterize this implementation?

A) Failure - no targets were met exactly
B) Largely successful - close to all targets with opportunity for optimization
C) Too early to judge
D) Complete success - time to stop measuring

---

## Answer Key

### Section 1: Multiple Choice

1. **B** - People and change management issues, not technical problems
   - *70% of change initiatives fail due to resistance, not technology.*

2. **B** - To test with a small group, learn, and adjust before scaling
   - *Pilots reduce risk by allowing learning before broad rollout.*

3. **B** - Acknowledge the concern, provide evidence, and make commitments
   - *Dismissing fears damages trust; acknowledgment and evidence build it.*

4. **B** - An early adopter who helps promote and support AI adoption with peers
   - *Champions are peer influencers who model positive adoption.*

5. **C** - AI suggestion acceptance rate (early adoption signal)
   - *Leading indicators predict future success; lagging indicators measure outcomes.*

6. **B** - Regularly throughout - before, during, and after launch
   - *Continuous communication builds trust and addresses concerns proactively.*

7. **C** - Start with agent-assistance tools (lower risk), then customer-facing AI (higher risk)
   - *Sequence from lowest to highest risk reduces implementation failures.*

8. **B** - Making mistakes during learning acceptable and encouraging honest feedback
   - *Safety comes from knowing learning errors won't be punished.*

9. **B** - Testing how ROI changes under different assumptions
   - *Sensitivity analysis shows range of outcomes, not just best case.*

10. **B** - Realistic benefits accounting for adoption curve and implementation costs
    - *Year 1 often includes heavy implementation costs and ramp-up time.*

### Section 2: True/False

11. **False** - Pilots provide learnings but don't guarantee scale success. Different challenges emerge at full scale.

12. **False** - Both are critical. Executive support without agent buy-in still fails, and vice versa.

13. **False** - Vanity metrics don't indicate quality or impact. Better: acceptance rate, quality scores, outcomes.

14. **True** - SARAH describes common emotional stages during change.

15. **False** - Change management continues through continuous improvement, new features, and ongoing support.

### Section 3: Scenario-Based

16. **B** - Investigate why the 2 agents are resistant, address concerns, and extend pilot if needed
    - *Understanding resistance informs broader rollout; forcing compliance backfires.*

17. **B** - Show the full 3-year picture with payback period and total ROI
    - *Transparent presentation builds credibility; hiding data raises suspicions.*

18. **B** - Potential "rubber-stamping" - agents may not be reviewing suggestions carefully
    - *95% acceptance without editing suggests insufficient review.*

19. **B** - Week -4: Announce → Week -2: Train champions → Week 0: Pilot → Week +2: Share results
    - *Proper sequence builds awareness, prepares champions, and demonstrates value.*

20. **B** - Largely successful - close to all targets with opportunity for optimization
    - *Missing targets by small margins while showing improvement indicates success requiring optimization.*

---

## Scoring Guide

| Score | Grade | Interpretation |
|-------|-------|----------------|
| 18-20 | A | Excellent - Ready to lead AI implementation |
| 16-17 | B | Good - Strong understanding with minor gaps |
| 14-15 | C | Satisfactory - Review change management principles |
| 12-13 | D | Needs Improvement - Revisit module content |
| Below 12 | F | Unsatisfactory - Complete module review required |

---

## Concept Review

If you scored below 70%, review these areas:

**Change Management (Questions 1, 3, 8, 14):**
- Why implementations fail
- Handling resistance
- Psychological safety
- Change stages (SARAH)

**Phased Rollout (Questions 2, 7, 11, 16):**
- Purpose of pilots
- Feature sequencing
- Scaling considerations

**Stakeholder Management (Questions 4, 6, 12, 19):**
- Champion programs
- Communication planning
- Building buy-in

**Measurement (Questions 5, 9, 10, 13, 17, 18, 20):**
- Leading vs. lagging indicators
- Vanity metrics
- ROI presentation
- Interpreting results

---

## Implementation Readiness Checklist

Before starting AI implementation:

```
PLANNING
[ ] Current state assessed
[ ] Pain points identified
[ ] AI solution selected
[ ] Phased rollout designed
[ ] Timeline established

STAKEHOLDERS
[ ] All groups identified
[ ] Concerns mapped
[ ] Champions recruited
[ ] Communication plan ready

CHANGE MANAGEMENT
[ ] Key messages developed
[ ] Resistance responses prepared
[ ] Feedback channels established
[ ] Training designed

MEASUREMENT
[ ] Success metrics defined
[ ] Baselines captured
[ ] Dashboards designed
[ ] Reporting cadence set

RISK MANAGEMENT
[ ] Risks identified
[ ] Mitigations planned
[ ] Exit criteria defined
[ ] Escalation paths set

ROI
[ ] Costs calculated
[ ] Benefits quantified
[ ] Assumptions documented
[ ] Sensitivity analyzed
```

---

*Quiz 8 of 9 | AI for Customer Service Teams | Duration: 20 minutes*
