# Module 4 Quiz: Managing AI Risk & Governance

**Instructions**: Answer all questions. Select the best answer for multiple choice questions.

**Passing Score**: 70% (14 out of 20 points)

**Time Limit**: 20 minutes

---

## Section 1: Multiple Choice (10 questions, 1 point each)

### Question 1
What is "AI hallucination"?

A) When AI becomes self-aware
B) When AI generates confident but false information
C) When AI refuses to respond
D) When AI is dreaming

### Question 2
What is "model drift"?

A) AI moving to a different server
B) AI performance degrading over time as conditions change
C) AI becoming smarter automatically
D) AI being copied without permission

### Question 3
What is "historical bias" in AI?

A) AI preferring older data
B) Past discrimination patterns encoded in training data
C) AI having memory of all conversations
D) AI studying history topics

### Question 4
Which is a HIGH-RISK AI application requiring significant oversight?

A) Document summarization
B) Automated hiring decisions
C) Email spell-checking
D) Meeting note taking

### Question 5
What does GDPR require for automated decision-making?

A) All AI decisions must be made by humans
B) Users have the right to explanation and human review
C) AI must be built in Europe
D) No requirements for AI

### Question 6
What is "prompt injection" in AI security?

A) Improving prompts with examples
B) Malicious inputs designed to manipulate AI behavior
C) Automatically generating prompts
D) Teaching AI new skills

### Question 7
What is the purpose of an AI Ethics Board?

A) To approve all AI purchases
B) To provide strategic oversight and policy guidance on AI ethics
C) To write AI code
D) To replace human decision-makers

### Question 8
When should you conduct AI bias testing?

A) Only after complaints are received
B) Before AND after deployment, continuously
C) Only during initial development
D) Never - AI is unbiased by design

### Question 9
What is "Tier 1" AI risk classification typically reserved for?

A) Low-risk productivity tools
B) High-risk AI with significant impact on people's lives
C) Medium-risk business applications
D) All AI systems equally

### Question 10
What should happen FIRST when an AI incident is detected?

A) Complete a full root cause analysis
B) Stop ongoing harm and assess severity
C) Issue a press release
D) Blame the vendor

---

## Section 2: True/False (5 questions, 1 point each)

### Question 11
True or False: AI trained on historical data will automatically be unbiased if the algorithm is well-designed.

### Question 12
True or False: Putting confidential company information into public AI tools like ChatGPT creates security risks.

### Question 13
True or False: AI governance should be proportional to the risk level of the AI application.

### Question 14
True or False: The EU AI Act completely bans all use of AI in Europe.

### Question 15
True or False: Human oversight is recommended for high-stakes AI decisions affecting people's lives.

---

## Section 3: Scenario-Based Questions (5 questions, 1 point each)

### Question 16
**Scenario**: Your AI customer service chatbot suddenly starts giving wrong answers about product returns policy.

**Question**: What is the MOST likely cause?

A) The AI has become sentient
B) Model drift - policies changed but AI wasn't updated
C) Customers are asking wrong questions
D) The server is too slow

### Question 17
**Scenario**: An AI hiring tool rejects 80% of female applicants but only 40% of male applicants for similar roles.

**Question**: What type of problem is this?

A) A feature, not a bug
B) Disparate impact indicating potential bias
C) Normal statistical variation
D) A hardware malfunction

### Question 18
**Scenario**: An employee wants to use ChatGPT to help draft a merger announcement, including specific deal terms.

**Question**: What should you advise?

A) Go ahead - ChatGPT is secure
B) Don't share confidential deal terms with public AI tools
C) Only use it after the announcement
D) Use a longer prompt

### Question 19
**Scenario**: Your AI fraud detection system flags 10% more transactions from a particular demographic group.

**Question**: What should you do?

A) Ignore it - AI is objective
B) Investigate whether this reflects bias or actual risk patterns
C) Immediately remove demographic data
D) Turn off the AI system permanently

### Question 20
**Scenario**: A Tier 1 (high-risk) AI system is being deployed. What level of oversight is appropriate?

A) No oversight needed - let AI decide
B) Full review, human oversight, continuous monitoring, documentation
C) Annual review is sufficient
D) Only check if complaints are received

---

## Answer Key

### Section 1: Multiple Choice

1. **B** - When AI generates confident but false information
   - *Explanation: Hallucination is when AI produces plausible-sounding but incorrect content.*

2. **B** - AI performance degrading over time as conditions change
   - *Explanation: Drift occurs when the world changes but the model doesn't adapt.*

3. **B** - Past discrimination patterns encoded in training data
   - *Explanation: Historical data containing bias leads to biased AI.*

4. **B** - Automated hiring decisions
   - *Explanation: Decisions significantly affecting people's lives require highest oversight.*

5. **B** - Users have the right to explanation and human review
   - *Explanation: GDPR Article 22 provides rights regarding automated decisions.*

6. **B** - Malicious inputs designed to manipulate AI behavior
   - *Explanation: Prompt injection attempts to override AI instructions.*

7. **B** - To provide strategic oversight and policy guidance on AI ethics
   - *Explanation: Ethics boards set direction and standards, not operational execution.*

8. **B** - Before AND after deployment, continuously
   - *Explanation: Bias can emerge at any stage and conditions change over time.*

9. **B** - High-risk AI with significant impact on people's lives
   - *Explanation: Tier 1 requires most controls due to highest potential impact.*

10. **B** - Stop ongoing harm and assess severity
    - *Explanation: Immediate containment comes before investigation.*

### Section 2: True/False

11. **False** - Algorithms learn from data; biased historical data produces biased AI regardless of algorithm quality.

12. **True** - Public AI tools may store or use input data; confidential information shouldn't be shared.

13. **True** - Risk-proportionate governance applies more controls to higher-risk applications.

14. **False** - The EU AI Act regulates AI by risk level; it doesn't ban AI entirely.

15. **True** - High-stakes decisions should have human oversight to catch AI errors.

### Section 3: Scenario-Based

16. **B** - Model drift - policies changed but AI wasn't updated
    - *Explanation: AI giving outdated information suggests the model needs updating.*

17. **B** - Disparate impact indicating potential bias
    - *Explanation: Significant outcome differences between groups signals bias concern.*

18. **B** - Don't share confidential deal terms with public AI tools
    - *Explanation: Confidential business information shouldn't go into public AI.*

19. **B** - Investigate whether this reflects bias or actual risk patterns
    - *Explanation: Disparities need investigation to determine if bias or legitimate factors.*

20. **B** - Full review, human oversight, continuous monitoring, documentation
    - *Explanation: Tier 1 high-risk systems require comprehensive controls.*

---

## Scoring Guide

| Score | Grade | Performance Level |
|-------|-------|-------------------|
| 18-20 | A | Excellent - Strong risk awareness |
| 16-17 | B | Good - Solid understanding with minor gaps |
| 14-15 | C | Satisfactory - Meets minimum requirements |
| Below 14 | F | Review module content and retake quiz |

---

## Review Recommendations

**If you scored below 70%**, review these sections:

- Questions 1-3 wrong: Review "AI Limitations and Failures" and "Bias and Fairness"
- Questions 4-6 wrong: Review "Privacy and Security Risks" and "Regulatory Landscape"
- Questions 7-10 wrong: Review "Governance Frameworks" and "Building Responsible AI"
- Scenario questions wrong: Practice with the risk assessment exercise

---

*Quiz 4 of 6 | Introduction to AI for Business Professionals | 20 points total*
