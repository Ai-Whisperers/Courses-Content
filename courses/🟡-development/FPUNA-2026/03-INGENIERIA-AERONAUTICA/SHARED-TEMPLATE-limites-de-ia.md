# âš–ï¸ LÃ­mites de IA: DÃ³nde Confiar y DÃ³nde Cuestionar

## ğŸ¯ TEMPLATE - Adaptable a cada mÃ³dulo

**Instrucciones de uso**:
1. Copiar esta secciÃ³n completa
2. Reemplazar {MÃ“DULO}, {EJEMPLOS}, {TAREAS} segÃºn el mÃ³dulo especÃ­fico
3. Insertar despuÃ©s de la introducciÃ³n y antes del contenido tÃ©cnico

---

## âš–ï¸ LÃ­mites de IA: DÃ³nde Confiar y DÃ³nde Cuestionar

### FilosofÃ­a Fundamental

> **"La IA acelera la ejecuciÃ³n de lo que ya sabes hacer, no reemplaza tu criterio de ingeniero"**

En {MÃ“DULO}, OpenCode es un **asistente tÃ©cnico poderoso**, pero **NO un ingeniero aeronÃ¡utico**. Entender esta distinciÃ³n es crÃ­tico para tu Ã©xito profesional.

---

## ğŸ¤– Lo que IA Hace EXCELENTEMENTE

### 1. Tareas Repetitivas con Patrones Conocidos

**Ejemplos en {MÃ“DULO}**:
- {EJEMPLO_1: ej. "Generar 100 variantes de perfiles NACA"}
- {EJEMPLO_2: ej. "Calcular propiedades mÃ¡sicas de 50 componentes"}
- {EJEMPLO_3: ej. "Exportar modelos a 5 formatos diferentes"}

**Por quÃ© funciona**:
- âœ… PatrÃ³n conocido y repetible
- âœ… No requiere juicio creativo
- âœ… Resultado validable objetivamente

**Velocidad**: **10-15Ã— mÃ¡s rÃ¡pido** que manual

---

### 2. OptimizaciÃ³n en Espacio de Soluciones Conocido

**Ejemplos en {MÃ“DULO}**:
- {EJEMPLO_1: ej. "Encontrar Ã¡ngulo Ã³ptimo de flap entre 0-45Â°"}
- {EJEMPLO_2: ej. "Ajustar espesor de pared para minimizar peso"}
- {EJEMPLO_3: ej. "Distribuir refuerzos para maximizar rigidez"}

**Por quÃ© funciona**:
- âœ… Espacio de bÃºsqueda finito y definido
- âœ… FunciÃ³n objetivo clara (minimizar/maximizar)
- âœ… Restricciones conocidas

**Mejora tÃ­pica**: **20-40% mejor** que intuiciÃ³n inicial

---

### 3. SÃ­ntesis y DocumentaciÃ³n de InformaciÃ³n

**Ejemplos en {MÃ“DULO}**:
- {EJEMPLO_1: ej. "Generar reporte tÃ©cnico desde modelo CAD"}
- {EJEMPLO_2: ej. "Crear tabla comparativa de 10 configuraciones"}
- {EJEMPLO_3: ej. "Documentar decisiones de diseÃ±o automÃ¡ticamente"}

**Por quÃ© funciona**:
- âœ… Datos estructurados disponibles
- âœ… Formato de salida estÃ¡ndar
- âœ… No requiere interpretaciÃ³n creativa

**Velocidad**: **20Ã— mÃ¡s rÃ¡pido** que escritura manual

---

### 4. DetecciÃ³n de AnomalÃ­as en Datos HistÃ³ricos

**Ejemplos en {MÃ“DULO}**:
- {EJEMPLO_1: ej. "Detectar inconsistencias en geometrÃ­as"}
- {EJEMPLO_2: ej. "Identificar parÃ¡metros fuera de rango normal"}
- {EJEMPLO_3: ej. "Alertar sobre convergencia sospechosa en simulaciones"}

**Por quÃ© funciona**:
- âœ… Baseline de "normalidad" entrenado con datos histÃ³ricos
- âœ… Desviaciones detectables estadÃ­sticamente
- âœ… Alertas reducen errores humanos

**Beneficio**: **Reduce errores 60-80%**

---

## ğŸ§  Lo que IA Hace POBREMENTE (Requiere TU Juicio)

### 1. InnovaciÃ³n Verdadera sin Precedentes

**Ejemplos en {MÃ“DULO}**:
- âŒ {EJEMPLO_NEGATIVO_1: ej. "DiseÃ±ar vortex generators en raÃ­z de ala"}
  - **Por quÃ© falla**: Requiere intuiciÃ³n fÃ­sica sobre separaciÃ³n de flujo
  - **Tu rol**: Entender mecÃ¡nica de fluidos, pruebas en tÃºnel de viento
  
- âŒ {EJEMPLO_NEGATIVO_2: ej. "Inventar nueva topologÃ­a estructural"}
  - **Por quÃ© falla**: No hay datos histÃ³ricos de soluciones similares
  - **Tu rol**: Creatividad basada en principios de ingenierÃ­a

- âŒ {EJEMPLO_NEGATIVO_3: ej. "Optimizar para criterios contradictorios no cuantificables"}
  - **Por quÃ© falla**: No puede balancear "estÃ©tica vs funcionalidad" sin definiciÃ³n clara
  - **Tu rol**: Trade-offs basados en experiencia y contexto

**SeÃ±al de alerta**: Si la IA sugiere algo "nunca visto antes", **desconfÃ­a y valida rigurosamente**.

---

### 2. Decisiones de Seguridad CrÃ­ticas

**Ejemplos en {MÃ“DULO}**:
- âŒ {EJEMPLO_SEGURIDAD_1: ej. "Seleccionar factor de seguridad estructural"}
  - **Por quÃ© falla**: Depende de normativa, riesgo aceptable, consecuencias de falla
  - **Tu rol**: Aplicar FAA/EASA/DINAC, considerar peor caso, certificaciÃ³n

- âŒ {EJEMPLO_SEGURIDAD_2: ej. "Validar que diseÃ±o cumple normas aeronÃ¡uticas"}
  - **Por quÃ© falla**: Regulaciones requieren interpretaciÃ³n legal + tÃ©cnica
  - **Tu rol**: Responsabilidad legal del ingeniero firmante

- âŒ {EJEMPLO_SEGURIDAD_3: ej. "Decidir si componente es 'suficientemente seguro'"}
  - **Por quÃ© falla**: "Suficientemente" es juicio basado en consecuencias, no cÃ¡lculo
  - **Tu rol**: Ã‰tica profesional y responsabilidad civil

**Regla de oro**: **NUNCA confÃ­es en IA para decisiones que pongan vidas en riesgo**.

---

### 3. ComprensiÃ³n de Contexto y Restricciones ImplÃ­citas

**Ejemplos en {MÃ“DULO}**:
- âŒ {EJEMPLO_CONTEXTO_1: ej. "DiseÃ±ar considerando disponibilidad de materiales en Paraguay"}
  - **Por quÃ© falla**: No conoce mercado local, tiempos de importaciÃ³n, costos reales
  - **Tu rol**: Conocimiento del ecosistema productivo paraguayo

- âŒ {EJEMPLO_CONTEXTO_2: ej. "Optimizar para manufactura con capacidades locales"}
  - **Por quÃ© falla**: No sabe quÃ© CNC, impresoras 3D, o procesos estÃ¡n disponibles en AsunciÃ³n
  - **Tu rol**: Network de proveedores, capacidad de talleres locales

- âŒ {EJEMPLO_CONTEXTO_3: ej. "Balancear costo vs performance segÃºn presupuesto cliente"}
  - **Por quÃ© falla**: No entiende sensibilidad al precio de diferentes sectores (agrÃ­cola vs defensa)
  - **Tu rol**: Inteligencia de mercado y negociaciÃ³n

**Restricciones implÃ­citas** (que IA no ve): Cultura de trabajo, preferencias cliente, limitaciones polÃ­ticas, calendario, relaciones personales.

---

### 4. Trade-offs con Criterios Subjetivos

**Ejemplos en {MÃ“DULO}**:
- âŒ {EJEMPLO_TRADEOFF_1: ej. "Â¿DiseÃ±o simple y robusto vs Ã³ptimo pero complejo?"}
  - **Por quÃ© falla**: "Simple" y "robusto" no son mÃ©tricas objetivas
  - **Tu rol**: Considerar mantenibilidad, habilidad de operadores, filosofÃ­a de diseÃ±o

- âŒ {EJEMPLO_TRADEOFF_2: ej. "Â¿Maximizar performance vs minimizar costo?"}
  - **Por quÃ© falla**: No sabe el punto de equilibrio para TU cliente especÃ­fico
  - **Tu rol**: Entender prioridades reales del proyecto (a veces implÃ­citas)

- âŒ {EJEMPLO_TRADEOFF_3: ej. "Â¿Usar tecnologÃ­a probada vs innovar?"}
  - **Por quÃ© falla**: No puede medir riesgo reputacional, tolerancia a fallo del cliente
  - **Tu rol**: GestiÃ³n de riesgo basada en stakeholders

**Estos juicios** requieren empatÃ­a, experiencia, y entendimiento del problema humano detrÃ¡s del tÃ©cnico.

---

## ğŸ¯ Estrategia HÃ­brida: Workflow Humano-IA Ã“ptimo

```mermaid
%%{init: {'theme':'base', 'themeVariables': {'fontSize':'16px'}}}%%
graph TD
    Start[ğŸ“‹ Problema de IngenierÃ­a] --> Q1{Â¿Es tarea<br/>repetitiva?}
    
    Q1 -->|SÃ­| AI1[ğŸ¤– IA Lidera<br/>Humano valida]
    Q1 -->|No| Q2{Â¿Requiere<br/>innovaciÃ³n?}
    
    Q2 -->|SÃ­| H1[ğŸ§  Humano Lidera<br/>IA asiste]
    Q2 -->|No| Q3{Â¿DecisiÃ³n de<br/>seguridad?}
    
    Q3 -->|SÃ­| H2[ğŸ§  Humano Decide<br/>IA provee datos]
    Q3 -->|No| Q4{Â¿Trade-off<br/>subjetivo?}
    
    Q4 -->|SÃ­| H3[ğŸ§  Humano Balancea<br/>IA explora opciones]
    Q4 -->|No| AI2[ğŸ¤– IA Ejecuta<br/>Humano supervisa]
    
    AI1 --> Valid[âœ… Validar resultado]
    AI2 --> Valid
    H1 --> Valid
    H2 --> Valid
    H3 --> Valid
    
    Valid --> End[âœ… SoluciÃ³n Validada]
    
    style AI1 fill:#FFD700
    style AI2 fill:#FFD700
    style H1 fill:#0d47a1
    style H2 fill:#0d47a1
    style H3 fill:#0d47a1
    style Valid fill:#1b5e20
```

---

## ğŸ“‹ Checklist: Â¿CuÃ¡ndo Confiar en IA?

Antes de aceptar resultado de IA, pregÃºntate:

### âœ… ConfÃ­a (con validaciÃ³n) SI:

- [ ] La tarea es repetitiva y con patrÃ³n conocido
- [ ] El espacio de soluciones es finito y bien definido
- [ ] Puedes validar el resultado objetivamente (nÃºmeros, geometrÃ­a, lÃ³gica)
- [ ] NO afecta seguridad crÃ­tica directamente
- [ ] Tienes datos histÃ³ricos de referencia para comparar
- [ ] El error es recuperable (puedes rehacer si falla)
- [ ] Entiendes la lÃ³gica que IA deberÃ­a seguir
- [ ] Puedes explicar el resultado a un colega ingeniero

**AcciÃ³n**: Usa IA, pero **valida siempre** antes de proceder.

---

### âš ï¸ DesconfÃ­a SI:

- [ ] Es la primera vez que resuelves este tipo de problema
- [ ] Requiere innovaciÃ³n o creatividad verdadera
- [ ] Involucra juicios de seguridad o regulaciones
- [ ] Hay trade-offs subjetivos (estÃ©tica, preferencias, cultura)
- [ ] NO entiendes cÃ³mo IA llegÃ³ a ese resultado
- [ ] El resultado "parece demasiado bueno para ser verdad"
- [ ] Hay contexto implÃ­cito que IA no conoce (mercado, polÃ­tica, personas)
- [ ] Un error tendrÃ­a consecuencias graves

**AcciÃ³n**: Usa IA para **explorar opciones**, pero **TÃš decides** con anÃ¡lisis crÃ­tico.

---

### âŒ NUNCA ConfÃ­es SI:

- [ ] DecisiÃ³n afecta seguridad de personas (vida/muerte)
- [ ] CertificaciÃ³n legal requiere firma de ingeniero
- [ ] Cliente/regulador exige responsabilidad humana
- [ ] Consecuencias de error son irreversibles
- [ ] No puedes explicar el resultado (black box total)

**AcciÃ³n**: IA puede proveer **datos de entrada**, pero **humano toma decisiÃ³n final**.

---

## ğŸ” SeÃ±ales de Alerta: CuÃ¡ndo la IA "Alucina"

### Red Flags que indican resultado invÃ¡lido:

1. **NÃºmeros sospechosos**:
   - Eficiencias >100% (viola termodinÃ¡mica)
   - Factores de seguridad <1.0 (estructura fallarÃ­a)
   - Velocidades que violan fÃ­sica (Mach 5 con motor elÃ©ctrico)

2. **Contradicciones internas**:
   - "DiseÃ±o liviano pero muy resistente" (sin justificar cÃ³mo)
   - "Barato y de alta calidad" (sin especificar trade-off)

3. **Ignorancia de restricciones**:
   - GeometrÃ­a que no se puede fabricar
   - Materiales no disponibles en Paraguay
   - Procesos que requieren equipos inexistentes localmente

4. **Falta de incertidumbre**:
   - IA da respuestas con 100% confianza en problemas complejos
   - No menciona supuestos o limitaciones

**QuÃ© hacer**: Si ves estas seÃ±ales, **detente y valida manualmente** antes de proceder.

---

## ğŸ“ Casos de Estudio: CuÃ¡ndo Confiar vs Desconfiar

### Caso 1: DiseÃ±o de Perfil Alar

**Escenario**: Necesitas diseÃ±ar perfil alar para UAV agrÃ­cola.

| Tarea | IA Rol | Humano Rol | Confianza |
|-------|--------|------------|-----------|
| Generar coordenadas NACA 0012 | **IA ejecuta** (ecuaciÃ³n conocida) | Valida espesor mÃ¡ximo | âœ… Alta |
| Seleccionar NACA 0012 vs 4415 | IA compara datos | **Humano decide** (depende de misiÃ³n) | âš ï¸ Media |
| Inventar perfil completamente nuevo | âŒ IA no puede | **Humano diseÃ±a** (requiere CFD + pruebas) | âŒ Nula |

---

### Caso 2: {CASO_ESPECÃFICO_MÃ“DULO}

{DESCRIPCIÃ“N_CASO}

| Tarea | IA Rol | Humano Rol | Confianza |
|-------|--------|------------|-----------|
| {TAREA_1} | {ROL_IA_1} | {ROL_HUMANO_1} | {CONFIANZA_1} |
| {TAREA_2} | {ROL_IA_2} | {ROL_HUMANO_2} | {CONFIANZA_2} |
| {TAREA_3} | {ROL_IA_3} | {ROL_HUMANO_3} | {CONFIANZA_3} |

---

## ğŸ’¡ Consejos PrÃ¡cticos para Uso Efectivo

### 1. Siempre Valida con "Sanity Checks"

```
Ejemplo en {MÃ“DULO}:
- IA genera diseÃ±o estructural
- TÃš verificas:
  âœ“ Â¿CG estÃ¡ en posiciÃ³n razonable? (30-40% cuerda)
  âœ“ Â¿Peso total es realista? (no 100g ni 500kg para UAV 3kg)
  âœ“ Â¿Dimensiones son manufacturables? (espesor >0.5mm)
  âœ“ Â¿Materiales existen y son accesibles en Paraguay?
```

---

### 2. Documenta Supuestos de IA

Cuando uses IA, **anota**:
- Â¿QuÃ© datos de entrada usÃ³?
- Â¿QuÃ© supuestos hizo implÃ­citamente?
- Â¿QuÃ© restricciones NO considerÃ³?

**Esto te salva** cuando cliente pregunta "Â¿por quÃ© diseÃ±aste asÃ­?" 6 meses despuÃ©s.

---

### 3. Usa IA para Explorar, Humano para Decidir

**Workflow correcto**:
1. IA genera 10 opciones de diseÃ±o (rÃ¡pido)
2. TÃš eliminas 7 por razones prÃ¡cticas (contexto local)
3. IA simula las 3 restantes en detalle (acelera anÃ¡lisis)
4. TÃš seleccionas final considerando todos los factores

**Workflow INCORRECTO**:
1. IA genera 1 opciÃ³n "Ã³ptima"
2. TÃš la aceptas sin cuestionar âŒ

---

### 4. MantÃ©n tu Criterio Afilado

**Peligro**: Si usas IA para TODO, pierdes habilidad de pensamiento crÃ­tico.

**SoluciÃ³n**: Alterna entre:
- Problemas resueltos con IA (velocidad)
- Problemas resueltos manualmente (mantener habilidad)

**Frecuencia sugerida**: 70% con IA, 30% manual (para entrenamiento continuo).

---

## ğŸ¯ Resumen: Reglas de Oro

1. **IA acelera, NO reemplaza** tu conocimiento de ingenierÃ­a
2. **Siempre valida** resultados de IA antes de usar
3. **Nunca confÃ­es en IA** para decisiones de seguridad crÃ­tica
4. **Documenta supuestos** cuando uses IA
5. **MantÃ©n tu criterio afilado** con prÃ¡ctica manual regular
6. **Contexto local importa** (Paraguay â‰  USA â‰  Europa)
7. **Si no lo entiendes, no lo uses** (principio de responsabilidad)

---

**PrÃ³xima secciÃ³n**: {SIGUIENTE_SECCIÃ“N_DEL_MÃ“DULO}
