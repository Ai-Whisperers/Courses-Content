# =============================================================================
# ‚ö° PERFORMANCE RULES - REGLAS DE PERFORMANCE
# Basado en: Google SRE, Netflix Performance, Microsoft Azure Best Practices
# Proyecto: FPUNA AI Education - Lead Architect Performance Standards
# =============================================================================

meta:
  version: "1.0.0"
  last_updated: "2025-01-30"
  maintainer: "FPUNA AI Education Team"
  scope: ["performance", "optimization", "monitoring"]

# =============================================================================
# üéØ OBJETIVOS DE PERFORMANCE
# =============================================================================

targets:
  # Google SRE: Four Golden Signals
  latency:
    user_facing:
      p50: "< 100ms"
      p95: "< 500ms"
      p99: "< 1000ms"
    
    internal_services:
      p50: "< 50ms"
      p95: "< 200ms"
      p99: "< 500ms"
    
    background_jobs:
      avg: "Depends on workload"
      max: "Should not affect user latency"
  
  traffic:
    measurement: "Requests per second (RPS)"
    targets:
      api: "1000 RPS per instance"
      web: "500 RPS per instance"
      database: "10000 queries/sec"
  
  errors:
    target_rate: "< 0.1%"
    classification:
      user_errors: "< 5% of total errors"
      server_errors: "< 0.1% of total requests"
      timeout_errors: "< 0.01% of total requests"
  
  saturation:
    cpu: "< 70% average, < 90% peak"
    memory: "< 80% average, < 95% peak"
    disk_io: "< 70% utilization"
    network: "< 60% bandwidth"
    database_connections: "< 80% pool capacity"

# =============================================================================
# üìä M√âTRICAS Y MONITORING
# =============================================================================

monitoring:
  # Required metrics
  required_metrics:
    application:
      - "Request count"
      - "Response time (p50, p95, p99)"
      - "Error rate"
      - "Active connections"
      - "Queue depth"
    
    system:
      - "CPU utilization"
      - "Memory usage"
      - "Disk I/O"
      - "Network I/O"
    
    business:
      - "User satisfaction"
      - "Task completion rate"
      - "Revenue per request"
  
  # Dashboards
  dashboards:
    overview:
      - "Traffic volume"
      - "Error rate"
      - "Latency percentiles"
      - "System health"
    
    detailed:
      - "Per-endpoint metrics"
      - "Per-region metrics"
      - "Dependency performance"
      - "Resource utilization"
  
  # Alerting
  alerts:
    severity_levels:
      critical:
        latency_p99: "> 2000ms for 5 min"
        error_rate: "> 1% for 2 min"
        saturation: "> 90% for 5 min"
      
      warning:
        latency_p95: "> 1000ms for 10 min"
        error_rate: "> 0.5% for 5 min"
        saturation: "> 80% for 10 min"
      
      info:
        latency_p50: "> 200ms sustained"
        unusual_traffic: "> 2x baseline"

# =============================================================================
# üîß OPTIMIZACI√ìN DE C√ìDIGO
# =============================================================================

optimization:
  # Python-specific
  python:
    use:
      - "List comprehensions over map/filter"
      - "Generators for large datasets"
      - "f-strings for formatting"
      - "pathlib over os.path"
      - "built-in functions (sum, any, all)"
      - "appropriate data structures"
    
    avoid:
      - "String concatenation in loops"
      - "range(len()) pattern"
      - "Deep nesting (> 4 levels)"
      - "Global variables"
      - "Import *"
      - "Reflection/introspection in hot paths"
    
    libraries:
      prefer:
        - "numpy for numerical operations"
        - "pandas for data manipulation"
        - "asyncio for I/O bound"
        - "multiprocessing for CPU bound"
        - "lru_cache for memoization"
  
  # Database
  database:
    queries:
      - "Use indexes effectively"
      - "Avoid N+1 queries"
      - "Select only needed columns"
      - "Use pagination for large results"
      - "Batch inserts/updates"
      - "EXPLAIN queries in development"
    
    schema:
      - "Proper indexing strategy"
      - "Denormalize when read-heavy"
      - "Partition large tables"
      - "Use appropriate data types"
    
    connection_pooling:
      min_connections: 5
      max_connections: 20
      timeout: 30
  
  # Caching
  caching:
    strategy: "Cache-Aside (Lazy Loading)"
    
    when_to_cache:
      - "Expensive computations"
      - "Database queries (read-heavy)"
      - "External API calls"
      - "Session data"
    
    ttl_guidelines:
      user_data: "5-15 minutes"
      reference_data: "1-24 hours"
      static_content: "1-7 days"
      
    invalidation:
      - "Time-based (TTL)"
      - "Event-based (on update)"
      - "Version-based"
    
    tools: ["Redis", "Memcached", "in-memory (LRU)"]
  
  # Async operations
  async:
    use_for:
      - "I/O bound operations"
      - "External API calls"
      - "Database operations"
      - "File operations"
    
    avoid_for:
      - "CPU-intensive tasks"
      - "Synchronous libraries"
    
    patterns:
      - "async/await syntax"
      - "Gather for concurrent ops"
      - "Timeouts on all external calls"
      - "Circuit breakers"

# =============================================================================
# üåê OPTIMIZACI√ìN WEB
# =============================================================================

web_performance:
  # Frontend
  frontend:
    assets:
      - "Minify CSS/JS"
      - "Compress images (WebP)"
      - "Lazy loading for images"
      - "Code splitting"
    
    caching:
      - "Cache-Control headers"
      - "ETags for conditional requests"
      - "Service Workers for offline"
    
    delivery:
      - "CDN for static assets"
      - "HTTP/2 or HTTP/3"
      - "Brotli compression"
      - "Keep-alive connections"
  
  # API optimization
  api:
    payload:
      max_size: "1MB default, 10MB max"
      compression: "gzip for > 1KB"
    
    pagination:
      default_size: 20
      max_size: 100
      cursor_based: "preferred"
    
    batching:
      - "Accept multiple operations"
      - "Limit batch size (max 100)"
    
    partial_response:
      - "Field selection (?fields=)"
      - "Reduce payload size"

# =============================================================================
# üóÑÔ∏è OPTIMIZACI√ìN BASES DE DATOS
# =============================================================================

database_optimization:
  # Query optimization
  queries:
    n_plus_one:
      detection: "Enable SQL logging in dev"
      prevention: "Use eager loading (select_related, prefetch_related)"
    
    select_star:
      forbidden: true
      reason: "Retrieves unnecessary data"
      solution: "Explicit column selection"
    
    missing_indexes:
      detection: "EXPLAIN ANALYZE"
      common_fields: ["foreign keys", "search fields", "sort fields"]
    
    slow_queries:
      threshold_ms: 100
      log_and_review: true
  
  # Schema optimization
  schema:
    indexes:
      required_for: ["WHERE clauses", "JOIN columns", "ORDER BY"]
      avoid_on: ["low cardinality columns", "frequently updated columns"]
      
    denormalization:
      when: "Read-heavy, write-rarely"
      example: "Count cache, aggregated data"
      maintenance: "Triggers or application logic"
      
    partitioning:
      when: "> 10M rows or > 10GB"
      strategies: ["Range (date)", "Hash (ID)", "List (category)"]
  
  # Connection management
  connections:
    pooling: "Mandatory"
    pool_size:
      min: 5
      max: 20
    
    timeouts:
      connect: 5
      query: 30
      
    cleanup:
      - "Close unused connections"
      - "Handle connection leaks"
      - "Monitor pool exhaustion"

# =============================================================================
# üöÄ ESCALABILIDAD
# =============================================================================

scalability:
  # Horizontal scaling
  horizontal:
    stateless_services: "Required"
    load_balancing: "Round-robin or least-connections"
    session_storage: "External (Redis)"
    file_storage: "Object storage (S3)"
    
  # Vertical scaling
  vertical:
    when: "Single-node optimization before horizontal"
    limits: "Cost and physical constraints"
    
  # Database scaling
  database_scaling:
    read_replicas:
      when: "Read-heavy workload"
      lag_tolerance: "< 1s for critical data"
      
    sharding:
      when: "> 100GB or > 100M rows"
      strategy: "by tenant_id, user_id, or date"
      
  # Caching strategy
  caching_strategy:
    layers:
      - "Browser cache (client-side)"
      - "CDN edge cache"
      - "Application cache (Redis)"
      - "Database cache"
    
    cache_warming:
      - "Pre-populate on deploy"
      - "Background refresh"
      - "Stale-while-revalidate"

# =============================================================================
# üîç PERFORMANCE TESTING
# =============================================================================

performance_testing:
  # Load testing
  load_testing:
    tools: ["Locust", "k6", "JMeter", "Gatling"]
    
    scenarios:
      steady_state:
        description: "Normal traffic load"
        duration: "1 hour"
        users: "Expected concurrent users"
      
      peak_load:
        description: "Maximum expected traffic"
        duration: "30 minutes"
        users: "2x expected concurrent"
      
      stress_test:
        description: "Find breaking point"
        duration: "Until failure or timeout"
        users: "Gradual increase to failure"
      
      spike_test:
        description: "Sudden traffic increase"
        pattern: "0 ‚Üí 100% load instantly"
        
  # Profiling
  profiling:
    tools:
      python: ["cProfile", "py-spy", "scalene"]
      memory: ["memory_profiler", "pympler"]
    
    when:
      - "Before optimization (baseline)"
      - "After optimization (verification)"
      - "When latency degrades"
      - "Regular health checks (monthly)"
    
    focus:
      - "Hot paths (frequently executed)"
      - "Bottlenecks (slowest parts)"
      - "Memory usage patterns"
      - "I/O wait times"

# =============================================================================
# ‚ö†Ô∏è ANTI-PATRONES DE PERFORMANCE
# =============================================================================

anti_patterns:
  - name: "N+1 Queries"
    problem: "Un query por cada item en loop"
    solution: "Eager loading o batch queries"
    
  - name: "Loading Everything"
    problem: "SELECT * o cargar datos innecesarios"
    solution: "Solo lo necesario, paginaci√≥n"
    
  - name: "Synchronous Everything"
    problem: "Esperar I/O secuencialmente"
    solution: "Async/await, batch operations"
    
  - name: "No Caching"
    problem: "Recomputar o re-fetch constantemente"
    solution: "Multi-level caching strategy"
    
  - name: "Big Ball of Data"
    problem: "Respuestas API enormes"
    solution: "Field selection, pagination, compression"
    
  - name: "Blocking the Event Loop"
    problem: "CPU work in async context"
    solution: "Run CPU work in thread pool"
    
  - name: "Memory Leaks"
    problem: "Acumulaci√≥n de objetos"
    solution: "Profile memory, proper cleanup"
    
  - name: "Unbounded Growth"
    problem: "Listas/datos crecen sin l√≠mite"
    solution: "Streaming, pagination, limits"

# =============================================================================
# üõ†Ô∏è HERRAMIENTAS Y UTILIDADES
# =============================================================================

tools:
  # Profiling
  profiling:
    - "py-spy: Sampling profiler (no code changes)"
    - "scalene: CPU + memory profiler"
    - "cProfile: Built-in deterministic profiler"
    - "line_profiler: Line-by-line profiling"
    
  # Benchmarking
  benchmarking:
    - "pytest-benchmark: For tests"
    - "timeit: Quick timing"
    - "hyperfine: CLI benchmarking"
    
  # Monitoring
  monitoring:
    - "Prometheus + Grafana: Metrics and dashboards"
    - "Datadog/NewRelic: APM"
    - "Jaeger/Zipkin: Distributed tracing"
    
  # Load testing
  load_testing:
    - "Locust: Python-based, programmable"
    - "k6: Modern, JavaScript-based"
    - "JMeter: Feature-rich, GUI"

# =============================================================================
# ‚úÖ CHECKLIST DE PERFORMANCE
# =============================================================================

checklists:
  development:
    - "[ ] Profiling antes de optimizar"
    - "[ ] Queries optimizadas (no N+1)"
    - "[ ] Caching strategy definida"
    - "[ ] Async donde aplique"
    - "[ ] Paginaci√≥n para listas"
    - "[ ] Compresi√≥n habilitada"
    
  before_release:
    - "[ ] Load testing completado"
    - "[ ] M√©tricas de baseline establecidas"
    - "[ ] Alertas configuradas"
    - "[ ] Capacity plan documentado"
    - "[ ] Database indexes verificados"
    
  monitoring:
    - "[ ] Dashboards funcionando"
    - "[ ] Alertas configuradas"
    - "[ ] Runbook de troubleshooting"
    - "[ ] On-call familiarizado"
    - "[ ] Load balancer health checks"
